{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxS48STxUPlL4bLmpsXxyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/langchain/blob/main/section_2/01_lcel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Expression Language\n",
        "\n",
        "LCEL（LangChain Expression Language）を使うことで、基本的なコンポーネントから複雑なチェーンを簡単に構築することができます。  \n",
        "今回は、「Prompt」「Model」「Output parser」をLCELでつなぎます。  \n",
        "なお、以下の公式ドキュメントを参考にしています。  \n",
        "https://python.langchain.com/docs/\n"
      ],
      "metadata": {
        "id": "NJ0ypAO3Nd9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ライブラリのインストール\n",
        "langchain-coreとlangchain-openaiをインストールします。  "
      ],
      "metadata": {
        "id": "rohh9-kEV-8q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo66c8k56kai"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-core langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Keyの設定\n",
        "OpneAIのAPIを使用するために必要な「API key」を設定します。  \n",
        "以下のコードの、  \n",
        "`os.environ[\"OPENAI_API_KEY\"] = \"Your API key\"`  \n",
        "における  \n",
        "`Your API key`の箇所を、自分のAPI keyに置き換えます。  \n",
        "OpenAIのAPI keyは、OpenAIのサイトで取得できます。   \n",
        "https://platform.openai.com/account/api-keys\n"
      ],
      "metadata": {
        "id": "j03EsJaHh4KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your API key\""
      ],
      "metadata": {
        "id": "4lkJr3dk89bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "API keyの流出にはリスクがあります。  \n",
        "他者に知られないように、慎重に扱ってください。"
      ],
      "metadata": {
        "id": "2lEUNEp9n95k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LCELの例\n",
        "以下は「Prompt」 、「Model」、そして「Output parser」をLCELによる組み合わせた例です。\n"
      ],
      "metadata": {
        "id": "jomNHjE3lPAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"{topic}に関するなぞなぞを考えてください。\")\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser  # LCELで複数のコンポーネントを1つにまとめる\n",
        "\n",
        "chain.invoke({\"topic\": \"柴犬\"})"
      ],
      "metadata": {
        "id": "nkswVM4r9BBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードでは、LCELを使って異なるコンポーネントを1つのチェーンにまとめています。  \n",
        "  \n",
        "「｜」は、異なるコンポーネントを連結し、あるコンポーネントからの出力を次のコンポーネントへの入力として渡します。  "
      ],
      "metadata": {
        "id": "FJTxjtr1U6tS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt\n",
        "Promptは辞書を取り込んで PromptValue を生成します。  \n",
        "PromptValueはプロンプトのラッパーで、Modelに渡すことができます。  "
      ],
      "metadata": {
        "id": "R-EsC3-wXvVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"私の{topic}を占ってください。\")\n",
        "prompt_value = prompt.invoke({\"topic\": \"金運\"})\n",
        "prompt_value"
      ],
      "metadata": {
        "id": "UpdKYrF_aSlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "PromptValueはModel に渡されます。  \n",
        "ModelにはLLMとChatModelがあります。  \n",
        "LLMは文章が入力で、ChatModelは文章のやりとりが入力です。  \n",
        "以下ではChatModelを使っていますが、ChatModelであればBaseMessageを出力します。  "
      ],
      "metadata": {
        "id": "Amu4mlbipoas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "message = chat_model.invoke(prompt_value)\n",
        "message"
      ],
      "metadata": {
        "id": "pLtGUh-vptBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ModelがLLMであれば、文字列を出力します。  "
      ],
      "metadata": {
        "id": "q0bfY__n2Fmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
        "message = llm.invoke(prompt_value)\n",
        "message"
      ],
      "metadata": {
        "id": "DLlMGznTp3io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output parser\n",
        "Output parserは、文字列かBaseMessageを入力として受け取ります。  \n",
        "以下では、StrOutputParserを使っていますが、これは単純に入力を文字列に変換します。"
      ],
      "metadata": {
        "id": "lu1zn9Qmsbue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "output_parser.invoke(message)"
      ],
      "metadata": {
        "id": "XBNwgut5seR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "コードの実行後は、OpenAIのサイトでAPIの使用量を確認しましょう。  \n",
        "https://platform.openai.com/account/usage"
      ],
      "metadata": {
        "id": "B8hdFAd6VIaz"
      }
    }
  ]
}